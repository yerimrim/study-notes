<aside>
ğŸ’¡

### Decision Trees (ì˜ì‚¬ê²°ì • íŠ¸ë¦¬)

1. **ë¶„ë¥˜ ì†ì„± ì„ íƒ (Training Set ì‚¬ìš©)**
    1. ì •ë³´ ì´ë“ìœ¨ (ë†’ì€ ê²ƒ ì„ íƒ)
        - ì •ë³´ ì—”íŠ¸ë¡œí”¼ (Information Entropy) (ì‘ì„ìˆ˜ë¡ ìˆœë„ê°€ ë†’ìŒ)
        $\mathrm{Ent(D)} =-\sum_{k=1}^{|Y|} p_klog_2p_k$
        - ì •ë³´ ì´ë“ (Information Gain)
        $\mathrm{Gain(D,a)=Ent(D)}-\sum_{v=1}^V\dfrac{|D^v|}{|D|}\mathrm{Ent(D^v)}$
        - ì •ë³´ ì´ë“ìœ¨ (Gain Ratio)
        **$\mathrm{Gain \space ratio  (D,a)=\dfrac{Gain(D,a)}{IV(a)}}$**
            
             **$\mathrm{IV(a)}=-\sum_{v=1}^{V}\dfrac{|D^v|}{|D|}log_2\dfrac{|D^v|}{|D|}$**
            
        
    2. ì§€ë‹ˆ ê³„ìˆ˜ (ë‚®ì€ ê²ƒ ì„ íƒ, ì‘ì„ìˆ˜ë¡ ìˆœë„ê°€ ë†’ìŒ)
        - $\mathrm{Gini(D^v)}=\sum_{k=1}^{|Y|}\sum_{k'\not=k}p_kp_{k'}=1-\sum_{k=1}^{|Y|}p_k^2$
        - $\mathrm{Gini}\space \mathrm{index(D,a)} = \sum_{v=1}^V \dfrac{|D^v|}{|D|}\mathrm{Gini}(D^v)$

1. **ê°€ì§€ì¹˜ê¸° (Pruning) (Validation Set ì‚¬ìš©)**
    1. ì‚¬ì „ ê°€ì§€ì¹˜ê¸° (Pre-pruning)
        - ìœ„ì—ì„œë¶€í„° ì„±ëŠ¥ í‰ê°€
    2. ì‚¬í›„ ê°€ì§€ì¹˜ê¸° (Post-pruning)
        - ë°‘ì—ì„œë¶€í„° ì„±ëŠ¥ í‰ê°€
</aside>

<aside>
ğŸ’¡

### SVM (ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ )

- Margin: $\dfrac{|w^Tx+b|}{||w||}$     , when ì´ˆí‰ë©´ $w^Tx+b=0$

1. ì„ í˜• ë¶„ë¦¬ ê°€ëŠ¥(Hard Margin SVM) â‡’ ì˜¤ë¥˜ í—ˆìš© x
    - $w^Tx_i+b\geq \delta$      $if \space y_i=1$
    - $w^Tx_i+b\leq -\delta$      $if \space y_i=-1$
    
    - $w^T_{new}x_i + b_{new} \geq 1$       $if \space y_i=1$
    - $w^T_{new}x_i + b_{new} \leq 1$       $if \space y_i=-1$
    
    - ìµœì í™”: $min_{w,b} \space \dfrac{1}{2} ||w||^2$    $s.t.\space \space y_i(w^Tx_i+b)\geq 1$

1. ì„ í˜• ë¶„ë¦¬ ë¶ˆê°€ëŠ¥(Soft Margin SVM) â‡’ ì•½ê°„ì˜ ì˜¤ë¥˜ í—ˆìš© o
    - ìµœì í™”: $min_{w,b} \space \dfrac{1}{2} ||w||^2 + C\sum_{i=1}^n l_{0,1}(y_i(w^Tx_i+b)-1)$
    
2. ì»¤ë„ ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  
</aside>
