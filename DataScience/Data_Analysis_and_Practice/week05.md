### 분류: 어떤 대상을 정해진 범주에 구분해 넣는 작업

- 이진분류: target = 2
- 다중분류: target ≥ 3

✅ 평가지표

- **오차행렬(Confusion Matrix)**: 실제값과 예측값이 어떻게 매칭되는지를 보여주는 표
        
- **정확도(accuracy)**: 실젯값과 예측값이 얼마나 일치되는지를 비율로 나타낸 평가지표 ${TP+TN\over TP+FP+FN+TN}$
- **정밀도(precision)**: 양성 예측의 정확도 ${TP\over TP+FP}$
⇒ 틀려서는 안 될 때
- **재현율(recall, sensitivity, TPR)**: 실제 양성값(TP+FN)중 양성(TP)으로 잘 예측한 값의 비율 ${TP\over TP+FN}$
⇒ 틀려도 됨. 광범위하게 제공
- **F1 score**: $2\times {precision\times recall \over precision + recall}$
- **Log Loss**: 타깃값을 확률로 예측할 때 기본적으로 사용하는 평가지표 (작을수록 좋음) $-{1\over N}\sum^N_{i=1}(y_ilog(\hat y_i)+(1-y_i)log(1-\hat y_i))$
- **ROC 커브**: 참 양성 비율(TPR)에 대한 거짓 양성 비율(FPR) 곡선
- **AUC**: ROC 커브 아래의 면적

---

### 회귀: 독립변수와 종속변수 간 관계를 모델링

⇒ 주어진 독립변수와 종속변수 사이의 관계를 기반으로 최적의 회귀계수를 찾아야 함.

- 독립변수: 영향을 미치는 변수
- 종속변수: 영향을 받는 변수
- 단순선형회귀: 독립변수 1개, 종속변수 1개
- 다중선형회귀: 독립변수 n≥2개, 종속변수 1개

✅ 평가지표

- MAE (평균절대오차): ${1\over N}\sum^N_{i=1}|y_i-\hat y_i|$
- MSE (평균제곱오차): ${1\over N}\sum_{i=1}^N(y_i-\hat y_i)^2$
- RMSE (평균제곱근오차): $\sqrt{MSE}$
- MSLE (정답과 예측에 각각 log를 취함, 1을 더함으로써 보정해줌): ${1\over N}\sum^N_{i=1}(log(y_i+1)-log(\hat y_i+1))^2$
- RMSLE: $\sqrt{MSLE}$
- R$^2$(결정계수, 1에 가까울수록 성능 ⬆️): ${\hat \sigma^2\over\sigma^2}$
- 상관계수: 두 변수 사이의 상관관께 정도를 수치로 나타낸 값
    - 피어슨 상관계수: 선형상관관계의 강도와 방향을 나타냄.
    $-1\leq \rho \leq 1$

---

- 데이터 인코딩
    1. 레이블 인코딩: 범주형 데이터를 숫자로 일대일 매핑해주는 인코딩 방식 (0,1,2,…)
    2. 원-핫 인코딩: 여러 값 중 하나(one)만 활성화(hot)하는 인코딩 (0,1)
- 피처 스케일링: 서로 다른 피처 값의 범위가 일치하도록 조정하는 작업
    1. min-max 정규화: 피처 값의 범위를 0~1로 조정하는 기법 
        
        ⇒ $x_{scaled}={x-x_{min}\over x_{max}-x_{min}}$
        
    2. 표준화(standardization): 평균이 0, 분산이 1이 되도록 피처 값을 조정하는 기법, 상한 하한 존재 x
        
        ⇒ $x_{scaled}={x-\bar x\over \sigma}$
        
- 교차 검증
    - K 폴드 교차 검증 (데이터 개수가 적을 때, 1,000개 이하)
    : 훈련 데이터를 k개 그룹으로 나눈 후, 하나의 그룹을 validation으로 활용하여 평가
     이를 k번 반복하여 평가점수의 평균을 구함
    - 층화 K 폴드 교차 검증 (타깃값 분포가 불균형할 때 사용)
    : 타깃값이 골고루 분포되게 폴드를 나누는 K 폴드 교차 검증 방법

---

### 머신러닝 모델

- 베이스라인 모델:
    - 선형 회귀:
    - 로지스틱 회귀: 선형 회귀 방식을 응용해 분류에 적용한 모델. 이진 분류 문제에서 사용.
    - 결정트리: 분류, 회귀 모두 사용 가능 (하이퍼파라미터: 불순도, 엔트로피, 정보이득, 지니불순도)
    - 앙상블: 다양한 모델이 내린 예측 결과를 결합하는 기법, 대체로 예측 성능이 좋아짐, 과대적합 방지 효과
        - 보팅: 서로 다른 예측 결과가 여러 개 있을 때 개별 결과를 종합해 최종 결과를 결정하는
        방식
            - 하드 보팅: ‘다수결 투표’ 방식으로 최종 예측값을 정하는 방식
            - 소프트 보팅: 개별 예측 확률들의 평균을 최종 예측확률로 정하는 방식
        - 배깅: 개별 모델로 예측한 결과를 결합해 최종 예측을 정하는 기법. ‘개별 모델이 서로
        다른 샘플링 데이터를 활용
        - 부스팅: 가중치를 활용해 분류 성능이 약한 모델을 강하게 만드는 기법
    - 랜덤포레스트: 결정 트리를 배깅 방식으로 결합한 모델, 결정 트리를 **병렬**로 배치, 분류 및 회귀 모두 사용 가능
- 부스팅 모델
    - XGBoost: 성능이 우수한 트리 기반 부스팅 알고리즘, 결정트리를 **직렬**로 배치해 사용, 직전 트리가 예측한 값을 다음 트리가 활용해서 예측값 을 조금씩 수정할 수 있다.
    - LightGBM: XGBoost와 성능은 비슷하지만 훈련 속도가 더 빠름, 
    단, 데이터 개수가 적을 때는 과대적합되기 쉽다 ⇒ 과대적합 방지용 하이퍼파라미터를 조정해야 함.

---

- 하이퍼파라미터 최적화
(초기 파라미터는 random ⇒ Loss를 최소화하도록 파라미터를 update)
    1. 그리드 서치: 주어진 하이퍼파라미터를 모두 순회
    2. 랜덤 서치: 하이퍼파라미터를 무작위로 탐색
    3. 베이지안 최적화: 사전 정보를 바탕으로 최적 하이퍼파라미터 값을 확률적으로 추정하며 탐색 (더 빠르고 효율적)
