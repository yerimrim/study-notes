```jsx
[딥러닝]
: 심층 신경망을 학습하는 다양한 방법
다층퍼셉트론으로 비선형 결정경계를 만들 수 있으나, 복잡한 문제에서는 성능이 제한됨
딥러닝은 hidden layer가 늘어나도 학습 가능, 복잡한 문제에서도 좋은 성능 (e.g. 음성인식, 영상인식, 패턴인식)

(다층 퍼셉트론에서의 문제)
1) 기울기 소멸 문제
	=> 시그모이드 함수 대신 ReLU 함수 사용하여 해결
2) 과적합 문제
	=> 드롭아웃, 규제화, 배치정규화
		 드롭아웃: 일정 확률로 노드를 무작위 선택, 선택된 노드의 앞뒤로 연결된 가중치 연결선은 무시하고 학습, 반복학습을 통해 심층신경망의 모든 weight 업데이트

심층신경망DNN + 머신러닝ML = 딥러닝DL

ML: 특징 추출, 분류
DL:	특징 추출 + 분류를 동시 자동적으로 수행 (단, 성능 증가 시 원인 파악 어려움, 즉 복잡함)

_________________________________________________________________________________________________________________________
[심층 신경망 DNN (Depp Neural Network)]
: 다층퍼셉트론보다 여러 개의 은닉층을 가진 신경망 계열의
	딥러닝 알고리즘 사용
	(e.g. 음성인식, 영상인식, 패턴인식)

정형화 데이터 <- 클래식 머신러닝 (배깅, 부스팅)
적은 양의 데이터 <- 클래식 머신러닝
많은 양의 데이터 <- 심층 신경망, 딥러닝

인공신경망의 종류
1) Fully-Connected, Undirected (DNN, RBM, DBM)
2) Convolutional (LeNet, GoogleNet, AlexNet, VGGNet, ResNet)
3) Recurrend (LSTM, GRU, SRU)

인공신경망 학습 기법
1) Activation Function (ReLU, Leaky ReLU, Maxout)
2) Regularization (Early Stopping, L1 L2 Regularization, Dropout)
3) Optimization (SGD, AdaGrad, RMSprop, Adam)
_________________________________________________________________________________________________________________________
[합성곱 신경망 & 순환 신경망]

<합성곱 신경망 CNN(Convolutional Neural Network)>
: 다차원 데이터를 학습하기 위한 인공신경망
이미지와 같은 공간적 상관관계
FFNN은 1차원만 가능 <-> CNN은 다차원 데이터 가능

(CNN 특징)
1) Locality
2) Shared Weights

<순환 신경망 RNN(Recurrent Neural Network)>
: 시계열 데이터 (현재, 이전 시점 값 고려 필요) (e.g. 음성, 자연어 문장, 동영상, 주가 변동)
이전 값들이 현재 값에 영향을 줌, 구성요소 간 순서 존재

FFNN,CNN - 현재 데이터
RNN - 과거의 출력데이터 참조
```
