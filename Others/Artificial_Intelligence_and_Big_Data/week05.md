```jsx
[비지도학습 & 강화학습]

<비지도학습>: 레이블이 없는 데이터의 규칙성을 스스로 찾아냄 (e.g. 데이터 마이닝)
비지도학습의 결과 => 지도학습의 입력
- 클러스터: 유사한 것들의 집합
- 클러스터링: 유사한 것끼리 그룹으로 묶는 작업 (e.g. 고객 분류, 유사 이미지 그룹화, 신용카드 사기 탐지, 네트워크 침입 탐지, 악성 활동 탐지)
*** 분류 != 클러스터링 (분류는 명확히 구분, 클러스터링은 유사한 것끼리 그룹화)**

(비지도학습 알고리즘)
K-means 군집화 알고리즘: 유사한 k개의 데이터 그룹으로 묶는 방법
	장점: 알고리즘이 비교적 간단, 수행속도 빠름
	단점: k, 최초 지정 중심에 따라 결과가 상이함

<강화학습>: 보상을 통해 스스로 학습 (e.g. 알파고)
_________________________________________________________________________________________________________________________
[신경망: 단층 퍼셉트론 SLP (Single-layer Perceptron)]
<신경망>
: 데이터의 특징을 자동으로 추출, 방대하고 복잡한 데이터 학습 및 인식에 특화
	역전파 알고리즘 사용

<표현학습 RL (Representing Learning)>
: 신경망을 활용하여 자동으로 추출된 데이터의 특징을 학습

Classic ML: Input -> Hand-designed Features(사람 개입 o) -> Mapping from features -> output
RL not DL: Input -> Features(사람 개입 x) -> Mapping from features -> output

(역사 속 3대 신경망 모델)
- 퍼셉트론
- 다층 퍼셉트론
- 심층 신경망

1957년 로젠블럿의 **마크 1 퍼셉트론** 개발 '곧 인공지능이 실현될 것이라는 기대감'
1969년 **단층 퍼셉트론**의 한계
1986년 힌튼, 럼멜하트 등이 **다층 퍼셉트론** 학습법 제안
1990년대 **심층신경망** 학습 잘 안 되는 현상
2006년 힌튼 등이 **딥러닝** 방법 제안
2012년 딥러닝을 이용한 세계 최대 이미지 인식 경연대회 ILSVRC 압도적 1위

<단층 퍼셉트론>: 입력 레이어와 출력 레이어로 구성된 가장 간단한 신경망 구조
- AND, OR 연산
- 단점: 선형분리가 가능한 패턴들만 분류 가능, XOR 문제 해결 불가능
_________________________________________________________________________________________________________________________
[신경망: 다층 퍼셉트론 MLP (Multi-layer Perceptron)]
- 단층 퍼셉트론 + 하나 이상의 은닉층 추가 => **입력층 -> 은닉층 -> 출력층**
- 역전파 알고리즘을 사용한 신경망 학습
- 노드의 입출력 특성이 비선형임
19080년 중반, 다층 퍼셉트론으로 비선형 문제, 즉 XOR 문제 해결 (단층 퍼셉트론 한계 극복)
오차: 기대출력값과 다층퍼셉트론 출력값의 차이
다층 퍼셉트론 학습: 오차가 최소가 되도록 '가중치(weight)'와 '편차(bias)'를 결정하는 것
	- 최대경사법: 편미분을 사용해 오차에 미치는 가중치의 영향 정도를 계산
	- 오차역전파 알고리즘: 최대경사법을 기반으로 값을 업데이트

1990년대 다층 퍼셉트론의 한계 = 기울기 소실, 과적합(히든레이어 증가 때문에 발생
```
